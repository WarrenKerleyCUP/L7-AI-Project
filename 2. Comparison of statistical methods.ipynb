{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Timeseries Methods - One example at a time\n",
    "\n",
    "Let's look at candidate methods for forecasting a single timeseries. These will be:\n",
    "\n",
    "- Holt-Winters (Exponential Smoothing)\n",
    "- SARIMAX\n",
    "- Prophet\n",
    "\n",
    "This notebook will look at one ISBN country example at at time (to allow me to focus!)\n",
    "\n",
    "The four candiates are:\n",
    "\n",
    "- ISBN 9788490369968 (a Kid's Box title) in Spain (ES)\n",
    "- ISBN 9781316628744 (a Kid's Box title) in Turkey (TR) - more peaky\n",
    "- ISBN 9781108457651 (an English Grammar in Use title) in South Korea (KR) - very sparse\n",
    "- ISBN 9780521174909 (a reader) in Spain (ES) - no clear pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from helpers import *\n",
    "\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import dateutil\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing as hwes\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redshift user credentials - set here\n",
    "USER = \n",
    "PASSWORD = \n",
    "\n",
    "FCST_PERIOD = 12   #How many months I want to forecast ahead - let's start witg full 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SQLAlchemy engine for Redshift database\n",
    "user = USER\n",
    "password = PASSWORD\n",
    "host= \n",
    "port='5439'\n",
    "dbname='prod'\n",
    "\n",
    "url = \"postgresql+psycopg2://{0}:{1}@{2}:{3}/{4}\".format(user, password, host, port, dbname)\n",
    "engine = create_engine(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get demand data from Amazon Redshift\n",
    "\n",
    "Read the demand data into a dataframe using a key list of the 3 ISBN/country combinations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = ['9788490369968ES',\n",
    "            '9781316628744TR',\n",
    "            '9781108457651KR',\n",
    "            '9780521174909ES']\n",
    "\n",
    "key = '9788490369968ES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    select \n",
    "        isbn + ship_to_country_key as key,\n",
    "        isbn,\n",
    "        ship_to_country_key as country,\n",
    "        last_day(date) as month,\n",
    "        sum(quantity_demanded) as qty\n",
    "    from r2ibp.f_demand_actual\n",
    "    where key = '{key}'\n",
    "    and month <= current_date\n",
    "    group by month, isbn, ship_to_country_key\n",
    "    order by month asc\n",
    "    \"\"\"\n",
    "\n",
    "conn = engine.connect()\n",
    "df_demand = pd.read_sql_query(query, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = convert_to_ts(df_demand, start = '2018-08-31') # so always plot full date range\n",
    "        \n",
    "plt.plot(ts)\n",
    "plt.grid()\n",
    "plt.title(key)      \n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Holt-Winters\n",
    "\n",
    "Let's start with hyperparameters already selected i.e. what I've used in later examples.\n",
    "\n",
    "I'll add a step on hyperparameter selection later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast using Holt-Winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "def predict_ts_using_hwes(df_demand, period, config = ['add', False, 'add', False]):\n",
    "    \n",
    "    t,d,s,b = config       \n",
    "      \n",
    "    ts_actuals = convert_to_ts(df_demand, period)\n",
    "    #Add a tiny value to avoid divide by zero errors\n",
    "    ts_actuals['qty'] += 1e-10   \n",
    "\n",
    "    ts_train = ts_actuals[:-period]\n",
    "    ts_test = ts_actuals[-period:]\n",
    "    ts_naive1 = ts_actuals[-(12+period):-12].shift(periods = 12, freq = 'M')\n",
    "\n",
    "    mod = hwes(ts_train,  \n",
    "            trend= t,\n",
    "            damped_trend = d,\n",
    "            seasonal= s,\n",
    "            use_boxcox = b,\n",
    "            seasonal_periods = 12,\n",
    "            initialization_method=\"estimated\",\n",
    "            freq = 'M'\n",
    "            )\n",
    "    res = mod.fit()\n",
    "    pred = res.predict(len(ts_train),len(ts_train)+(period-1))\n",
    "            \n",
    "    #If a negatve forecast, when using additive set to zero?\n",
    "    #220221 - play with this as should make HW worse\n",
    "    #pred[pred<0] = 0\n",
    "\n",
    "    df_forecast = ts_test.copy().reset_index()\n",
    "    df_forecast.insert(loc=0, column='key', value=key)\n",
    "    df_forecast.rename(columns = {'index':'month', 'qty':'actuals'}, inplace = True)\n",
    "    df_forecast['pred'] = pred.values\n",
    "    df_forecast['naive-1'] = ts_naive1['qty'].values\n",
    "   \n",
    "    return df_forecast\n",
    "\n",
    "\n",
    "def calc_rsme_values(df_forecast):\n",
    "    \n",
    "    y_test = df_forecast['actuals'] #Rename this when I tidy up!\n",
    "    yhat = df_forecast['pred']\n",
    "    y_naive1 = df_forecast['naive-1']       \n",
    "\n",
    "    rmse_pred = round(mean_squared_error(y_test, yhat, squared = False), 2)\n",
    "    rmse_naive1 = round(mean_squared_error(y_test, y_naive1, squared = False), 2)\n",
    "    \n",
    "    return rmse_pred, rmse_naive1\n",
    "\n",
    "\n",
    "def plot_preds_against_actuals(df_demand, df_forecast, period):\n",
    "   \n",
    "    key = df_demand['key'][0]\n",
    "    \n",
    "    ts_actuals = convert_to_ts(df_demand, period)\n",
    "    ts_naive1 = ts_actuals[-(12+period):-12].shift(periods = 12, freq = 'M')\n",
    "\n",
    "    #Reconstruct the HW forecast\n",
    "    ts_pred = df_forecast.copy()[['month', 'pred']]\n",
    "    ts_pred.set_index(pd.to_datetime(ts_pred.month), inplace=True)\n",
    "    ts_pred.drop(\"month\", axis=1, inplace=True)\n",
    "\n",
    "    plt.plot(ts_actuals[-24:], '-o', label=\"actuals\") #Only plot 2 years back\n",
    "    plt.plot(ts_pred, '-o', label=\"pred\")\n",
    "    plt.plot(ts_naive1, '-o', label=\"naive-1\")\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.title(key);\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search on config to find best HWES parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB This has to be done with training data only so need to lop FCST_PERIOD off df_demand\n",
    "\n",
    "current_date = dt.datetime.today()\n",
    "dt_fcst_period_ago = dt.date(current_date.year, current_date.month, 1)\\\n",
    "                            - dateutil.relativedelta.relativedelta(months=FCST_PERIOD)\n",
    "\n",
    "df_demand_search = df_demand.copy()\n",
    "df_demand_search = df_demand_search[df_demand_search['month'] < dt_fcst_period_ago]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "#Grid search likely to create lots of warnings\n",
    "#https://stackoverflow.com/questions/40105796/turn-warning-off-in-a-cell-jupyter-notebook\n",
    "\n",
    "configs = list()\n",
    "\n",
    "t_params = ['add', 'mul']   #trend\n",
    "d_params = [True, False]    #damped\n",
    "s_params = ['add', 'mul']   #seasonal\n",
    "b_params = [True, False]    #use_boxcox\n",
    "\n",
    "# create config instances\n",
    "for t in t_params:\n",
    "    for d in d_params:\n",
    "        for s in s_params:\n",
    "            for b in b_params:\n",
    "                cfg = [t,d,s,b] \n",
    "                configs.append(cfg)\n",
    "\n",
    "#Now score each config using RMSE\n",
    "scores = []\n",
    "\n",
    "for config in configs:\n",
    "    try:\n",
    "        df_hwes_forecast = predict_ts_using_hwes(df_demand_search, FCST_PERIOD, config)       \n",
    "        rmse_pred, _ = calc_rsme_values(df_hwes_forecast)\n",
    "    except:\n",
    "        rmse_pred = None\n",
    "     \n",
    "    scores.append([config, rmse_pred])\n",
    "    \n",
    "df_scores = pd.DataFrame(scores, columns = ['trend, damped, seasonal, BoxCox', 'rmse']).sort_values(by='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores\n",
    "\n",
    "#This will vary by case and I'll need at least 12 + 2 forecast periods to do this every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at what the best fit looks like for this combo\n",
    "config = df_scores.iloc[0,0]\n",
    "\n",
    "df_hwes_forecast = predict_ts_using_hwes(df_demand, FCST_PERIOD, config)\n",
    "plot_preds_against_actuals(df_demand, df_hwes_forecast, FCST_PERIOD)\n",
    "\n",
    "rmse_pred, rmse_naive1 = calc_rsme_values(df_hwes_forecast)\n",
    "print('RMSE pred =', rmse_pred)\n",
    "print('RMSE naive-1  =', rmse_naive1)\n",
    "print('Pred better than naive-1?', rmse_pred < rmse_naive1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with results for pre-selected hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = ['add', False, 'add', False]\n",
    "\n",
    "df_hwes_forecast = predict_ts_using_hwes(df_demand, FCST_PERIOD, config = CONFIG)\n",
    "\n",
    "plot_preds_against_actuals(df_demand, df_hwes_forecast, FCST_PERIOD)\n",
    "\n",
    "rmse_pred, rmse_naive1 = calc_rsme_values(df_hwes_forecast)\n",
    "print('RMSE pred =', rmse_pred)\n",
    "print('RMSE naive-1  =', rmse_naive1)\n",
    "print('Pred better than naive-1?', rmse_pred < rmse_naive1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SARIMAX\n",
    "\n",
    "Same as above and even more important to put in the hyperparameter selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast with SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is running a simple additative trend and additative seasonality model\n",
    "\n",
    "def predict_ts_using_SARIMAX(df_demand, period, order=(0,1,1), seasonal_order=(1,1,0,12)):\n",
    "    \n",
    "    #This is a repeat of HWES above\n",
    "    ts_actuals = convert_to_ts(df_demand, period)\n",
    "    ts_train = ts_actuals[:-period]\n",
    "    ts_test = ts_actuals[-period:]\n",
    "    ts_naive1 = ts_actuals[-(12+period):-12].shift(periods = 12, freq = 'M')\n",
    "    \n",
    "    mod = SARIMAX(\n",
    "        ts_train,\n",
    "        order=order,\n",
    "        seasonal_order=seasonal_order,\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False)\n",
    "\n",
    "    res = mod.fit()\n",
    "    pred = res.predict(len(ts_train),len(ts_train)+(period-1))\n",
    "    \n",
    "    #Append the results to df_forecasts\n",
    "    df_forecast = ts_test.copy().reset_index()\n",
    "    df_forecast.insert(loc=0, column='key', value=key)\n",
    "    df_forecast.rename(columns = {'index':'month', 'qty':'actuals'}, inplace = True)\n",
    "    df_forecast['pred'] = pred.values\n",
    "    df_forecast['naive-1'] = ts_naive1['qty'].values\n",
    "    \n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning SARIMAX.\n",
    "\n",
    "What is the best selection of order and seasonal order parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by looking at the timeseries\n",
    "\n",
    "Things to look at are:\n",
    "\n",
    "- Timeseries Decomposition\n",
    "- Autocorrelation\n",
    "- Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_actuals = convert_to_ts(df_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the timeseries decomposition\n",
    "#See M7/05 lesson for an example of this\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "#from statsmodels.tsa.seasonal import STL #Need to remind myself why used this\n",
    "\n",
    "res = seasonal_decompose(ts_actuals, two_sided = False)\n",
    "\n",
    "trend = res.trend\n",
    "seasonal = res.seasonal\n",
    "residual = res.resid\n",
    "\n",
    "# Plot the results\n",
    "#plt.subplots(figsize = (15,5))\n",
    "\n",
    "plt.plot(ts_actuals, label = 'Original')\n",
    "plt.plot(trend, label = 'Trend')\n",
    "plt.plot(seasonal, label = 'Seasonality')\n",
    "plt.plot(residual, label = 'Residuals')\n",
    "plt.title(key)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the autocorrelation\n",
    "#Uses pd.Series.autocorr\n",
    "\n",
    "lags = range(1, 25)\n",
    "autocorrs = [ts_actuals['qty'].autocorr(lag=lag) for lag in lags]\n",
    "plt.stem(lags, autocorrs, use_line_collection=True)\n",
    "plt.xlabel(\"Lag\", fontsize=12)\n",
    "plt.ylabel(\"Autocorrelation\", fontsize=12);\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the differencing\n",
    "#Which looks broadly stationary\n",
    "\n",
    "plt.plot(ts_actuals['qty'].diff(1))\n",
    "plt.grid()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the differenced version showing the yearly autocorrelation\n",
    "#NB There is also a PSCF version of this\n",
    "\n",
    "lags = range(1, 25)\n",
    "autocorrs = [ts_actuals['qty'].diff(1).autocorr(lag=lag) for lag in lags]\n",
    "plt.stem(lags, autocorrs, use_line_collection=True)\n",
    "plt.xlabel(\"Lag\", fontsize=12)\n",
    "plt.ylabel(\"Autocorrelation\", fontsize=12);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMAX (p,d,q)(P,D,Q,s) parameter search\n",
    "\n",
    "Let's brute force a solution here.\n",
    "Assume that only need to difference once and only ARMA a few steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "\n",
    "# Set p, and q to take values from 0 to 3. \n",
    "p = q = range(0, 4)\n",
    "# Set d to take 1\n",
    "d = range(1,2)\n",
    "\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "PDQs = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This didn't take long despite 16*16 permutations\n",
    "\n",
    "ts_train = ts_actuals[:-FCST_PERIOD]\n",
    "\n",
    "mse_values = []\n",
    "order_values = []\n",
    "\n",
    "for i in pdq:\n",
    "    for j in PDQs:\n",
    "    # Generate a SARIMA model with the selected parameters for the seasonal order\n",
    "        mod = SARIMAX(ts_train,\n",
    "                    order=i,\n",
    "                    seasonal_order=j,\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False,\n",
    "                    freq = 'M')\n",
    "    \n",
    "        results = mod.fit()\n",
    "        mse = results.mse\n",
    "       \n",
    "        mse_values.append(mse)\n",
    "        order_values.append([i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_index = mse_values.index(min(mse_values))\n",
    "best_params = order_values[min_index]\n",
    "\n",
    "print('Best training mse:', mse_values[min_index])\n",
    "print('Best params:', order_values[min_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SARIMAX_forecast = predict_ts_using_SARIMAX(df_demand,\n",
    "                                               FCST_PERIOD, order=best_params[0], seasonal_order=best_params[1])\n",
    "\n",
    "plot_preds_against_actuals(df_demand, df_SARIMAX_forecast, FCST_PERIOD)\n",
    "\n",
    "rmse_pred, rmse_naive1 = calc_rsme_values(df_SARIMAX_forecast)\n",
    "print('RMSE pred =', rmse_pred)\n",
    "print('RMSE naive-1  =', rmse_naive1)\n",
    "print('Pred better than naive-1?', rmse_pred < rmse_naive1)\n",
    "\n",
    "#This is actually worse than setting logically (see below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the residuals\n",
    "\n",
    "See L7 AI M7/06 i.e. that the difference between our prediction and actuals are uncorrelated and have zero mean.\n",
    "In fact there are other tests for checking any regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_residuals = df_SARIMAX_forecast.copy()\n",
    "df_residuals['qty'] = df_residuals['actuals'] - df_residuals['pred']\n",
    "\n",
    "print('Mean of residuals is', round(df_residuals['qty'].mean(),1))\n",
    "\n",
    "ts_residuals = df_residuals.copy()[['month', 'qty']]\n",
    "ts_residuals.set_index(pd.to_datetime(ts_residuals.month), inplace=True)\n",
    "ts_residuals.drop(\"month\", axis=1, inplace=True)\n",
    "\n",
    "plt.plot(ts_residuals)\n",
    "plt.grid()\n",
    "plt.title('Residuals')      \n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with results for pre-selected hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a default set of parameters that is equivalenet to same as last year (PDQs = 1,1,0,12)\n",
    "#And adjust based on the error term from last month (pdq = 0,1,1)\n",
    "\n",
    "ORDER=(0,1,1)\n",
    "SEASONAL_ORDER=(1,1,0,12)\n",
    "\n",
    "df_SARIMAX_forecast = predict_ts_using_SARIMAX(df_demand, FCST_PERIOD, order=ORDER, seasonal_order=SEASONAL_ORDER)\n",
    "\n",
    "plot_preds_against_actuals(df_demand, df_SARIMAX_forecast, FCST_PERIOD)\n",
    "\n",
    "rmse_pred, rmse_naive1 = calc_rsme_values(df_SARIMAX_forecast)\n",
    "print('RMSE pred =', rmse_pred)\n",
    "print('RMSE naive-1  =', rmse_naive1)\n",
    "print('Pred better than naive-1?', rmse_pred < rmse_naive1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prophet\n",
    "\n",
    "NB This works in a different way to the other two. It requires a dataframe formatted in a particular way\n",
    "\n",
    "See L7 AI M7/07\n",
    "The use of linear trend is justified because of the previous analyses for SARIMAX re the underlying trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ts_using_Prophet(df_demand, period):\n",
    "    \n",
    "    ts_actuals = df_demand.copy()[['month', 'qty']]\n",
    "    ts_actuals = ts_actuals.rename(columns={'month': 'ds', 'qty': 'y'}) \n",
    "    ts_train = ts_actuals[:-FCST_PERIOD]\n",
    "    ts_test = ts_actuals[-FCST_PERIOD:]\n",
    "    ts_naive1 = ts_actuals.copy()[-(12+FCST_PERIOD):-12]\n",
    "    ts_naive1['ds'] = ts_test['ds'].values\n",
    "    \n",
    "    mod = Prophet(\n",
    "        growth=\"linear\",\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=False,\n",
    "        yearly_seasonality=True)\n",
    "\n",
    "    res = mod.fit(ts_train)\n",
    "    pred = res.predict(ts_test)\n",
    "    \n",
    "    df_forecast = ts_test.copy()\n",
    "    df_forecast.insert(loc=0, column='key', value=key)\n",
    "    df_forecast.rename(columns = {'ds':'month', 'y':'actuals'}, inplace = True)\n",
    "    df_forecast['pred'] = pred['yhat'].to_list()\n",
    "    df_forecast['naive-1'] = ts_naive1['y'].to_list()\n",
    "    \n",
    "    return df_forecast\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Prophet_forecast = predict_ts_using_Prophet(df_demand, FCST_PERIOD)\n",
    "\n",
    "plot_preds_against_actuals(df_demand, df_Prophet_forecast, FCST_PERIOD)\n",
    "\n",
    "rmse_pred, rmse_naive1 = calc_rsme_values(df_Prophet_forecast)\n",
    "print('RMSE pred =', rmse_pred)\n",
    "print('RMSE naive-1  =', rmse_naive1)\n",
    "print('Pred better than naive-1?', rmse_pred < rmse_naive1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
